name: MA Cross Module Tests

on:
  push:
    branches: [main, develop]
    paths:
      - 'app/ma_cross/**'
      - 'app/tools/**'
      - 'tests/**'
      - '.github/workflows/ma_cross_tests.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'app/ma_cross/**'
      - 'app/tools/**'
      - 'tests/**'
  schedule:
    # Run regression tests daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - e2e
          - performance
          - regression
          - smoke

# Version configuration: Uses defaults from .github/actions/setup-python-poetry/action.yml
# See .versions file for canonical version reference
env:
  PYTHON_VERSION: '3.11'

jobs:
  test:
    name: Test Suite
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-suite:
          - ${{ github.event.inputs.test_suite == 'all' && 'smoke' || github.event.inputs.test_suite || 'smoke' }}
          - ${{ github.event.inputs.test_suite == 'all' && 'unit' || '' }}
          - ${{ github.event.inputs.test_suite == 'all' && 'integration' || '' }}
          - ${{ github.event.inputs.test_suite == 'all' && 'regression' || '' }}
        exclude:
          - test-suite: ''
      fail-fast: false

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python with Poetry
        uses: ./.github/actions/setup-python-poetry
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          # poetry-version uses default from action (see .versions file)
          dependency-groups: 'all'
          cache-key-suffix: 'ma-cross-${{ matrix.test-suite }}'

      - name: Lint code
        run: |
          poetry run ruff check app/ma_cross/ app/tools/ --output-format=github
        continue-on-error: true

      - name: Type check
        run: |
          poetry run mypy app/ma_cross/ app/tools/ --ignore-missing-imports
        continue-on-error: true

      - name: Run ${{ matrix.test-suite }} tests
        run: |
          # Run tests directly with pytest instead of custom runner
          if [ "${{ matrix.test-suite }}" = "smoke" ]; then
            poetry run pytest tests/strategies/ma_cross/ -v -m "smoke" --tb=short
          elif [ "${{ matrix.test-suite }}" = "unit" ]; then
            poetry run pytest tests/strategies/ma_cross/ -v -m "unit" --cov=app/ma_cross --cov-report=xml --cov-report=term-missing -n auto
          elif [ "${{ matrix.test-suite }}" = "integration" ]; then
            poetry run pytest tests/strategies/ma_cross/ -v -m "integration" --tb=short
          elif [ "${{ matrix.test-suite }}" = "regression" ]; then
            poetry run pytest tests/strategies/ma_cross/ -v -m "regression" --tb=short
          fi
        timeout-minutes: 30

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ma-cross-test-results-${{ matrix.test-suite }}
          path: |
            .coverage
            coverage.xml
            .pytest_cache/
          retention-days: 30

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        if: matrix.test-suite == 'unit' || matrix.test-suite == 'all'
        with:
          file: ./coverage.xml
          flags: ma-cross
          name: codecov-ma-cross
          fail_ci_if_error: false

  # E2E tests removed - no E2E tests currently exist for MA Cross module
  # The module has comprehensive unit (31 tests) and integration (39 tests) coverage
  # E2E tests would require full-stack Docker environment and real market data

  summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [test]
    if: always()

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v6

      - name: Generate summary
        run: |
          echo "# MA Cross Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check test results
          if [ "${{ needs.test.result }}" == "success" ]; then
            echo "✅ **Unit/Integration/Regression Tests**: PASSED" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Unit/Integration/Regression Tests**: FAILED" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Coverage" >> $GITHUB_STEP_SUMMARY
          echo "- 31 unit tests" >> $GITHUB_STEP_SUMMARY
          echo "- 39 integration tests" >> $GITHUB_STEP_SUMMARY
          echo "- Regression tests run on schedule" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- Test results and coverage reports are available in the artifacts section" >> $GITHUB_STEP_SUMMARY
          echo "- All test results are retained for 30 days" >> $GITHUB_STEP_SUMMARY
