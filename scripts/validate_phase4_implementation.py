#!/usr/bin/env python3
"""
Phase 4 Implementation Validation Script

This script validates the Phase 4 advanced caching and monitoring implementation
by testing key functionality and measuring performance improvements.
"""

import os
import sys
import tempfile
import time
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    import pandas as pd
    import polars as pl

    from app.tools.export.unified_export import (
        AdvancedCache,
        ExportConfig,
        PerformanceMetrics,
        PerformanceMonitor,
        UnifiedExportProcessor,
    )
    from app.tools.portfolio.base_extended_schemas import SchemaType

    print("âœ… Successfully imported Phase 4 components")
except ImportError as e:
    print(f"âŒ Import error: {e}")
    sys.exit(1)


def test_advanced_cache():
    """Test the AdvancedCache implementation."""
    print("\n=== Testing AdvancedCache ===")

    cache = AdvancedCache(ttl_minutes=60, max_entries=100)

    # Test basic operations
    cache.put("key1", "value1", "hash1")
    result = cache.get("key1")
    assert result == "value1", "Basic cache put/get failed"
    print("âœ… Basic cache operations working")

    # Test TTL
    cache_short_ttl = AdvancedCache(ttl_minutes=0.01)  # ~0.6 seconds
    cache_short_ttl.put("temp_key", "temp_value", "temp_hash")
    assert cache_short_ttl.get("temp_key") == "temp_value", "Immediate access failed"

    time.sleep(0.7)
    assert cache_short_ttl.get("temp_key") is None, "TTL expiration failed"
    print("âœ… TTL expiration working")

    # Test content-based invalidation
    cache.put("key2", "value2", "hash2")
    cache.put("key3", "value3", "hash2")  # Same hash
    cache.invalidate_by_content("hash2")

    assert cache.get("key2") is None, "Content invalidation failed for key2"
    assert cache.get("key3") is None, "Content invalidation failed for key3"
    assert cache.get("key1") == "value1", "Content invalidation affected wrong key"
    print("âœ… Content-based invalidation working")

    # Test cache statistics
    stats = cache.get_stats()
    assert "hit_count" in stats, "Cache stats missing hit_count"
    assert "miss_count" in stats, "Cache stats missing miss_count"
    assert "hit_ratio" in stats, "Cache stats missing hit_ratio"
    print("âœ… Cache statistics working")


def test_performance_monitor():
    """Test the PerformanceMonitor implementation."""
    print("\n=== Testing PerformanceMonitor ===")

    monitor = PerformanceMonitor(enable_alerts=True, threshold_ms=50.0)

    # Test metrics recording
    metrics = PerformanceMetrics(
        total_time=0.03,
        schema_validation_time=0.01,
        file_write_time=0.01,
        cache_hit=True,
        cache_type="schema_validation",
    )

    monitor.record_metrics(metrics)
    summary = monitor.get_performance_summary()

    assert summary["total_operations"] == 1, "Metrics recording failed"
    assert summary["average_total_time_ms"] == 30.0, "Average time calculation failed"
    assert summary["cache_hit_ratio"] == 1.0, "Cache hit ratio calculation failed"
    print("âœ… Performance monitoring working")

    # Test alert system
    alert_triggered = False

    def test_alert_callback(metrics):
        nonlocal alert_triggered
        alert_triggered = True

    monitor.add_alert_callback(test_alert_callback)

    slow_metrics = PerformanceMetrics(total_time=0.1)  # 100ms > 50ms threshold
    monitor.record_metrics(slow_metrics)

    assert alert_triggered, "Performance alert not triggered"
    print("âœ… Performance alerting working")


def test_unified_export_processor_phase4():
    """Test the Phase 4 enhancements to UnifiedExportProcessor."""
    print("\n=== Testing UnifiedExportProcessor Phase 4 ===")

    with tempfile.TemporaryDirectory() as temp_dir:
        config = ExportConfig(
            output_dir=temp_dir,
            cache_schema_validation=True,
            enable_export_result_caching=True,
            cache_ttl_minutes=60,
            cache_max_entries=100,
            enable_performance_alerts=False,  # Disable for testing
            performance_threshold_ms=50.0,
        )

        processor = UnifiedExportProcessor(config)

        # Create test data
        test_data = pd.DataFrame(
            {
                "Ticker": ["AAPL", "GOOGL"],
                "Open [%]": [1.0, 2.0],
                "High [%]": [1.1, 2.1],
                "Low [%]": [0.9, 1.9],
                "Close [%]": [1.05, 2.05],
                "Volume [%]": [1000000, 2000000],
            }
        )

        # Test export result caching
        filename = "test_export.csv"

        # First export - should not hit cache
        result1 = processor.export_single(test_data, filename)
        assert result1.success, "First export failed"
        assert not result1.performance_metrics.get(
            "cache_hit", False
        ), "Unexpected cache hit on first export"
        print("âœ… First export successful (no cache hit)")

        # Second export with same data - should hit cache
        result2 = processor.export_single(test_data, filename)
        assert result2.success, "Second export failed"
        assert result2.performance_metrics.get(
            "cache_hit", False
        ), "Cache hit expected on second export"
        assert (
            result2.performance_metrics.get("cache_type") == "export_result"
        ), "Wrong cache type"
        print("âœ… Second export successful (cache hit)")

        # Test cache diagnostics
        diagnostics = processor.get_cache_diagnostics()
        assert "schema_cache" in diagnostics, "Missing schema_cache in diagnostics"
        assert (
            "export_result_cache" in diagnostics
        ), "Missing export_result_cache in diagnostics"
        assert (
            "cache_configuration" in diagnostics
        ), "Missing cache_configuration in diagnostics"
        print("âœ… Cache diagnostics working")

        # Test performance summary
        summary = processor.get_performance_summary()
        assert "schema_cache" in summary, "Missing schema_cache in summary"
        assert (
            "export_result_cache" in summary
        ), "Missing export_result_cache in summary"
        assert (
            "combined_cache_hit_ratio" in summary
        ), "Missing combined_cache_hit_ratio in summary"
        assert (
            "cache_efficiency_score" in summary
        ), "Missing cache_efficiency_score in summary"
        print("âœ… Enhanced performance summary working")

        # Test cache invalidation
        initial_cache_size = diagnostics["export_result_cache"]["cache_size"]
        processor.invalidate_cache()

        post_clear_diagnostics = processor.get_cache_diagnostics()
        final_cache_size = post_clear_diagnostics["export_result_cache"]["cache_size"]

        assert final_cache_size == 0, "Cache invalidation failed"
        print("âœ… Cache invalidation working")


def test_content_hash_generation():
    """Test content hash generation for caching."""
    print("\n=== Testing Content Hash Generation ===")

    with tempfile.TemporaryDirectory() as temp_dir:
        config = ExportConfig(output_dir=temp_dir)
        processor = UnifiedExportProcessor(config)

        test_data = pd.DataFrame({"A": [1, 2], "B": [3, 4]})

        # Same parameters should generate same hash
        hash1 = processor._generate_content_hash(
            test_data, "test.csv", "AAPL", "SMA", "TEST"
        )
        hash2 = processor._generate_content_hash(
            test_data, "test.csv", "AAPL", "SMA", "TEST"
        )
        assert hash1 == hash2, "Same parameters should generate same hash"
        print("âœ… Consistent hash generation working")

        # Different parameters should generate different hash
        hash3 = processor._generate_content_hash(
            test_data, "different.csv", "AAPL", "SMA", "TEST"
        )
        assert hash1 != hash3, "Different parameters should generate different hash"
        print("âœ… Hash differentiation working")


def test_batch_export_with_caching():
    """Test batch export functionality with Phase 4 caching."""
    print("\n=== Testing Batch Export with Caching ===")

    with tempfile.TemporaryDirectory() as temp_dir:
        config = ExportConfig(
            output_dir=temp_dir, enable_export_result_caching=True, max_workers=2
        )
        processor = UnifiedExportProcessor(config)

        # Create test data
        data1 = pd.DataFrame({"A": [1, 2], "B": [3, 4]})
        data2 = pd.DataFrame({"A": [5, 6], "B": [7, 8]})

        export_jobs = [
            (data1, "batch_1.csv", {}),
            (data2, "batch_2.csv", {}),
            (data1, "batch_1_dup.csv", {}),  # Same data for cache testing
        ]

        results = processor.export_batch(export_jobs)

        assert len(results) == 3, "Batch export count mismatch"
        assert all(r.success for r in results), "Some batch exports failed"
        print("âœ… Batch export with caching working")

        # Check for cache hits
        cache_hits = sum(
            1 for r in results if r.performance_metrics.get("cache_hit", False)
        )
        # Note: Cache hits may be 0 due to different filenames, but test should still pass
        print(f"âœ… Batch export completed with {cache_hits} cache hits")


def performance_benchmark():
    """Run performance benchmark to validate Phase 4 improvements."""
    print("\n=== Performance Benchmark ===")

    with tempfile.TemporaryDirectory() as temp_dir:
        # Test with caching enabled
        config_cached = ExportConfig(
            output_dir=temp_dir,
            enable_export_result_caching=True,
            cache_schema_validation=True,
        )
        processor_cached = UnifiedExportProcessor(config_cached)

        # Test with caching disabled
        config_no_cache = ExportConfig(
            output_dir=temp_dir,
            enable_export_result_caching=False,
            cache_schema_validation=False,
        )
        processor_no_cache = UnifiedExportProcessor(config_no_cache)

        # Create test data
        test_data = pd.DataFrame({"Ticker": ["AAPL"] * 100, "Value": list(range(100))})

        # Benchmark without caching
        start_time = time.time()
        for i in range(5):
            result = processor_no_cache.export_single(test_data, f"no_cache_{i}.csv")
            assert result.success, f"No-cache export {i} failed"
        no_cache_time = time.time() - start_time

        # Benchmark with caching (should show improvement on repeated exports)
        start_time = time.time()
        for i in range(5):
            # Use same filename to trigger export result caching
            result = processor_cached.export_single(test_data, "cached_export.csv")
            assert result.success, f"Cached export {i} failed"
        cached_time = time.time() - start_time

        print(f"No-cache time: {no_cache_time:.4f}s")
        print(f"Cached time: {cached_time:.4f}s")

        # Get cache statistics
        summary = processor_cached.get_performance_summary()
        hit_ratio = summary.get("combined_cache_hit_ratio", 0)
        print(f"Cache hit ratio: {hit_ratio:.2%}")

        if cached_time < no_cache_time:
            improvement = ((no_cache_time - cached_time) / no_cache_time) * 100
            print(f"âœ… Performance improvement: {improvement:.1f}%")
        else:
            print(
                "âš ï¸  No significant performance improvement (may be due to test overhead)"
            )


def main():
    """Main validation function."""
    print("ðŸš€ Starting Phase 4 Implementation Validation")
    print("=" * 60)

    try:
        test_advanced_cache()
        test_performance_monitor()
        test_unified_export_processor_phase4()
        test_content_hash_generation()
        test_batch_export_with_caching()
        performance_benchmark()

        print("\n" + "=" * 60)
        print("ðŸŽ‰ All Phase 4 validation tests passed!")
        print("âœ… Advanced caching implementation is working correctly")
        print("âœ… Performance monitoring is functioning properly")
        print("âœ… Export result caching is operational")
        print("âœ… Cache invalidation is working as expected")
        print("âœ… Phase 4 is ready for production deployment")

    except Exception as e:
        print(f"\nâŒ Validation failed with error: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
